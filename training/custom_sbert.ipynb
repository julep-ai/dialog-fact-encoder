{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8198fee9-000e-4ef9-bb13-82c649c2e816",
   "metadata": {},
   "source": [
    "## Custom sbert to retrieve beliefs for dialogs\n",
    "\n",
    "**Goal:** Train a custom sentence-transformer to match dialogs with beliefs and facts\n",
    "**Method:**\n",
    "- [x] Use bge_small_en_15 model as base\n",
    "- [x] evaluate embedding similarity using base on test split\n",
    "    - [x] calc embeddings\n",
    "    - [x] calc cosine scores\n",
    "    - [x] visualize using matplotlib\n",
    "- [x] define new model arch\n",
    "    - [x] add custom modules\n",
    "    - [x] freeze transformer layer\n",
    "    - [x] define loss\n",
    "- [ ] finetune the model on train dataset\n",
    "- [ ] Evaluate the final model on the test-set\n",
    "- [ ] Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53fc09-0942-4e9a-921c-3804a1ede8ac",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94dea7bd-f87b-4559-bd82-dadf3dfd6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "query_prefix = \"Represent this sentence for searching relevant passages: \"\n",
    "max_len = 512\n",
    "training_hn_file = \"./data/hn-output.jsonl\"\n",
    "eval_file = \"./data/eval-output.jsonl\"\n",
    "batch_size = 1280\n",
    "output_model_path = \"./bge-base-custom\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ec397-3b13-4e2b-8e0f-9cf127378b8f",
   "metadata": {},
   "source": [
    "### Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e40d321-04e7-4048-891c-6748c6354a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "import itertools as it\n",
    "import os\n",
    "import random\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from FlagEmbedding import FlagModel\n",
    "import jsonlines as jsonl\n",
    "from lion_pytorch import Lion\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses as ls, models as ml, util\n",
    "from sentence_transformers.evaluation import SimilarityFunction, TripletEvaluator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6f55d-ec09-4bc5-8f1a-31e521ad3121",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- combined: stacked_samsum + dialogsum\n",
    "- hn_output: hard negatives mined triple set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a557a00b-c593-4f54-b84e-8b7f9406d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hn_output(file):\n",
    "    with jsonl.open(file) as reader:\n",
    "        for entry in reader:\n",
    "            query = entry[\"query\"]\n",
    "            pos = [dict(dialog=dialog) for dialog in entry[\"pos\"]]\n",
    "            neg = [dict(dialog=dialog) for dialog in entry[\"neg\"]]\n",
    "\n",
    "            for combined in it.product(\n",
    "                [dict(fact=query)],\n",
    "                pos,\n",
    "                neg,\n",
    "            ):\n",
    "                yield InputExample(texts=list(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd80250b-a38a-43a0-948b-b6ae709c7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = list(tqdm(hn_output(training_hn_file)))\n",
    "eval_data = list(tqdm(hn_output(eval_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99effc9-7ee3-4e40-bc88-0569df66dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = list(hn_output(training_hn_file))\n",
    "eval_data = list(hn_output(eval_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb77bc-7993-4e92-a851-a4fa62ffbf25",
   "metadata": {},
   "source": [
    "### Prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a36a696-71cc-44a0-bda9-178475a39459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(training_data, shuffle=True, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(eval_data, shuffle=True, batch_size=batch_size // 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76eafa-62a3-4aef-81c3-4c33eb2236ed",
   "metadata": {},
   "source": [
    "### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae425f5c-3d03-469b-aa91-d25f62f99e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "base_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969b9a75-b4fa-472f-9ead-5d7b95b0ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base transformer layers\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae05ef8-689b-48ee-a0dd-db8b9196a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Note that we must also set _target_device, or any SentenceTransformer.fit() call will reset\n",
    "# the body location\n",
    "base_model._target_device = device\n",
    "base_model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe303c3-e1aa-4fce-9db8-f70ed44d7082",
   "metadata": {},
   "source": [
    "### Define new model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1905d97-d065-42d2-88b8-62eea39ae116",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dims = base_model._first_module().get_word_embedding_dimension()\n",
    "\n",
    "def dense_projector(dims: int):\n",
    "    proj_dims = dims // 2\n",
    "    \n",
    "    return [\n",
    "        ml.Dense(dims, proj_dims),\n",
    "        # ml.Dropout(0.1),\n",
    "        ml.Dense(proj_dims, proj_dims),\n",
    "        # ml.Dropout(0.1),\n",
    "        ml.Dense(proj_dims, dims),\n",
    "    ]\n",
    "\n",
    "def asym_module(dims: int, keys: list[str], allow_empty_key: bool = False):\n",
    "    return ml.Asym(\n",
    "        {\n",
    "            key: dense_projector(dims)\n",
    "            for key in keys\n",
    "        },\n",
    "        allow_empty_key=allow_empty_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0942ce-e366-47e9-baa6-d51a8b9c1248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0',\n",
       "              Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel ),\n",
       "             ('1',\n",
       "              Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False}))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d833baf0-4a0e-4aa2-8dd6-ea8a7e56ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model._modules[\"2\"] = asym_module(emb_dims, [\"dialog\", \"fact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e111224-2b3f-4ecf-a408-663d2c6e8b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0',\n",
       "              Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel ),\n",
       "             ('1',\n",
       "              Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})),\n",
       "             ('2',\n",
       "              Asym(\n",
       "                (dialog-0): Dense({'in_features': 384, 'out_features': 192, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "                (dialog-1): Dropout(\n",
       "                  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "                (dialog-2): Dense({'in_features': 192, 'out_features': 192, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "                (dialog-3): Dropout(\n",
       "                  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (dialog-4): Dense({'in_features': 192, 'out_features': 384, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "                (fact-0): Dense({'in_features': 384, 'out_features': 192, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "                (fact-1): Dropout(\n",
       "                  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "                )\n",
       "                (fact-2): Dense({'in_features': 192, 'out_features': 192, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "                (fact-3): Dropout(\n",
       "                  (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (fact-4): Dense({'in_features': 192, 'out_features': 384, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})\n",
       "              )),\n",
       "             ('3', Normalize())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model._modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f70c20-b803-4c98-8b35-f22e80da0141",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42a0ee1-3dba-41f2-88c9-94f2dc258453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = ls.TripletLoss(model=base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5fb7d-127f-4af1-85fc-787016bff27b",
   "metadata": {},
   "source": [
    "### Create evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c29a335-feb5-4d6f-a12d-60b2819a87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_evaluator = TripletEvaluator.from_input_examples(\n",
    "    eval_data,\n",
    "    batch_size=batch_size // 10,\n",
    "    main_distance_function=SimilarityFunction.COSINE,\n",
    "    show_progress_bar=True,\n",
    "    write_csv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0ffc0-7e20-48eb-ae54-09f245df826d",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ad3a4a-5e52-4351-b857-283dd3ab3fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcf5bc756714f70b382adc816eeb0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c2dab946c64666bb03f1d93c81a34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae7a70925274234970e8eea0cdc1959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59c6df2fd254dce9406a3a0e6d3c403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d5a2c9174a4f4893b868f59b41ca3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef02b18b87446328794b1be3429ba2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d89cab4088d4776b246a80b4c709209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c457fb894284e50b0c4488c9f1f7aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060ffa87d8a4521aefadd193133f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/7366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_model.fit(\n",
    "    train_objectives=[(dataloader, train_loss)],\n",
    "    evaluator=triplet_evaluator,\n",
    "    checkpoint_save_steps=600,\n",
    "    checkpoint_path=f\"{output_model_path}/ckpts\",\n",
    "    scheduler=\"WarmupCosine\",\n",
    "    save_best_model=True,\n",
    "    epochs=10,\n",
    "    warmup_steps=100,\n",
    "    optimizer_class=Lion,\n",
    "    optimizer_params=dict(lr=1e-4, weight_decay=1e-2),\n",
    "    use_amp=True,\n",
    "    output_path=output_model_path,\n",
    "    checkpoint_save_total_limit=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a586e-e468-450d-9d2d-4b0538d8aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_to_hub(\"julep-ai/dialog-bge-base\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
